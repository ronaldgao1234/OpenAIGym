{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize(buckets, obs):\n",
    "    '''\n",
    "        Discretizes the continuous state values to a discrete value\n",
    "    '''\n",
    "    upper_bounds = [env.observation_space.high[0], 0.5, env.observation_space.high[2], math.radians(50)]\n",
    "    lower_bounds = [env.observation_space.low[0], -0.5, env.observation_space.low[2], -math.radians(50)]\n",
    "    ratios = [(obs[i] + abs(lower_bounds[i])) / (upper_bounds[i] - lower_bounds[i]) for i in range(len(obs))]\n",
    "    new_obs = [int(round((buckets[i] - 1) * ratios[i])) for i in range(len(obs))]\n",
    "    new_obs = [min(buckets[i] - 1, max(0, new_obs[i])) for i in range(len(obs))]\n",
    "    return tuple(new_obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epsilon_greedy_policy(action_probabilities, epsilon):\n",
    "    '''\n",
    "        Most of the time they choose an action that has maximal estimated action value \n",
    "        but with probability epsilon they choose an action at random\n",
    "        \n",
    "        Input:\n",
    "            np.array of action probabilities\n",
    "            \n",
    "        Returns:\n",
    "            Action to choose\n",
    "    '''\n",
    "    max_action_index = np.argmax(action_probabilities)\n",
    "    max_prob = 1 - epsilon + epsilon/len(action_probabilities)\n",
    "    other_prob = epsilon/len(action_probabilities)\n",
    "    probs = [max_prob if max_action_index == i else other_prob for i in range(len(action_probabilities))]\n",
    "    return np.random.choice(np.arange(len(action_probabilities)), p=probs)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_learning_rate(t):\n",
    "    min_lr = 0.1\n",
    "    decay = 25\n",
    "    return max(min_lr, min(1., 1. - math.log10((t + 1) / decay)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_action(env, action_probabilities, t):\n",
    "    epsilon = max(0.1, min(1., 1. - math.log10((t + 1) / 25))) # decaying epsilon\n",
    "    if np.random.random() < epsilon:\n",
    "        return env.action_space.sample()\n",
    "    else:\n",
    "        return np.argmax(action_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SARSA(env, buckets, max_episodes, max_iterations, gamma=1.0, epsilon=0.5):\n",
    "    Q = np.zeros(buckets + (env.action_space.n,))\n",
    "    \n",
    "    for i_episode in range(max_episodes):\n",
    "        state = discretize(buckets, env.reset())\n",
    "        \n",
    "        alpha = get_learning_rate(i_episode)\n",
    "        i = 0\n",
    "        done=False\n",
    "        \n",
    "        while not done and i != max_iterations: \n",
    "            action = get_action(env, Q[state], i_episode)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state = discretize(buckets, next_state)\n",
    "            next_action = get_action(env, Q[next_state], i_episode)\n",
    "            Q[state][action] += alpha * (reward + gamma * Q[next_state][next_action] - Q[state][action]) \n",
    "            state = next_state\n",
    "            action = next_action\n",
    "            i += 1\n",
    "            \n",
    "        if i_episode % 50 == 0:\n",
    "            print('Episode {}: Terminated at {} iterations'.format(i_episode, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0: Terminated at 11 iterations\n",
      "Episode 60: Terminated at 19 iterations\n",
      "Episode 120: Terminated at 86 iterations\n",
      "Episode 180: Terminated at 210 iterations\n",
      "Episode 240: Terminated at 151 iterations\n",
      "Episode 300: Terminated at 17 iterations\n",
      "Episode 360: Terminated at 144 iterations\n",
      "Episode 420: Terminated at 40 iterations\n",
      "Episode 480: Terminated at 188 iterations\n",
      "Episode 540: Terminated at 47 iterations\n",
      "Episode 600: Terminated at 62 iterations\n",
      "Episode 660: Terminated at 19 iterations\n",
      "Episode 720: Terminated at 20 iterations\n",
      "Episode 780: Terminated at 240 iterations\n",
      "Episode 840: Terminated at 175 iterations\n",
      "Episode 900: Terminated at 207 iterations\n",
      "Episode 960: Terminated at 182 iterations\n",
      "Episode 1020: Terminated at 221 iterations\n",
      "Episode 1080: Terminated at 39 iterations\n",
      "Episode 1140: Terminated at 88 iterations\n",
      "Episode 1200: Terminated at 473 iterations\n",
      "Episode 1260: Terminated at 269 iterations\n",
      "Episode 1320: Terminated at 141 iterations\n",
      "Episode 1380: Terminated at 267 iterations\n",
      "Episode 1440: Terminated at 239 iterations\n",
      "Episode 1500: Terminated at 410 iterations\n",
      "Episode 1560: Terminated at 500 iterations\n",
      "Episode 1620: Terminated at 199 iterations\n",
      "Episode 1680: Terminated at 500 iterations\n",
      "Episode 1740: Terminated at 185 iterations\n",
      "Episode 1800: Terminated at 219 iterations\n",
      "Episode 1860: Terminated at 500 iterations\n",
      "Episode 1920: Terminated at 233 iterations\n",
      "Episode 1980: Terminated at 257 iterations\n"
     ]
    }
   ],
   "source": [
    "SARSA(env, buckets, max_episodes, max_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
